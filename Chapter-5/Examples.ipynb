{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3b62d66",
   "metadata": {},
   "source": [
    "# Examples usage of different types of LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc33f5f",
   "metadata": {},
   "source": [
    "### Please refer to the respective sections in the book for further details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e515c7c8-b6d0-4bc5-a7cc-59a80773d93c",
   "metadata": {},
   "source": [
    "## Encoder-only example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f12b7f0-b2ea-4dd8-97e6-860088e9dc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e0f2daf36f40c8a9fe618cda78a449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63513480b5241429bd5a587bed8740d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7d8d2735284739a2188fd893a99e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d60c468f0194617a7b93f1cee64003c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3543ab2279d64ed382c8c4edb8a93cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Positive (Confidence: 0.57)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Sample text\n",
    "text = \"The new coffee flavor is amazing!\"\n",
    "\n",
    "# Encode text\n",
    "encoded_input = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "\n",
    "# Model prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoded_input)\n",
    "\n",
    "# Process prediction\n",
    "predictions = softmax(outputs.logits, dim=-1)\n",
    "\n",
    "# Output sentiment analysis\n",
    "sentiments = ['Negative', 'Positive']\n",
    "sentiment_score = predictions.numpy().flatten()\n",
    "sentiment_result = sentiments[sentiment_score.argmax()]\n",
    "\n",
    "print(f\"Sentiment: {sentiment_result} (Confidence: {sentiment_score.max():.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531466b2-5f13-4589-9610-efd479d5ad3b",
   "metadata": {},
   "source": [
    "## Decoder-only example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c4d2ed-f9f7-43f8-9d9c-447322449ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1883971b7d8a4c91a425760e2ff3091a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a world forgotten by time, an ancient city lies hidden somewhere on the horizon and a lost civilisation is trying to catch up with one. In A View from Earth, writer Paul Rynne explores the legacy of those characters for more than six hours, interviewing their heroes and their creators. To read Part Two of Rynne's fascinating work, click here.\n",
      "\n",
      "A view from earth, or in other media\n",
      "\n",
      "You're not living on a planet when you start visiting your relatives.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the GPT model using the pipeline API\n",
    "text_generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "# Define the prompt\n",
    "prompt = \"In a world forgotten by time, an ancient city lies hidden\"\n",
    "\n",
    "# Generate text based on the prompt\n",
    "generated_text = text_generator(prompt, max_length=100, num_return_sequences=1)\n",
    "\n",
    "print(generated_text[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453bdf89-bcc0-49e7-b2cb-56659d04fca5",
   "metadata": {},
   "source": [
    "## Encoder-Decoder example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd224b1-c0e3-4107-b980-2bbaf17c67cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa72f5e89b342dab38f6f27cc6f6917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec1a9318e37466baa01d665127755da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5838bf2e387a4ecf90c1c59ea602a099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a90c8da2351447e8e08d437ef0ad285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae55a2736d34a74be55328eca3b8af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d525553bef734c26add0bcb3f3468496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivamsolanki/Desktop/Generative-AI-book/gen-ai-book/lib/python3.10/site-packages/transformers/generation/utils.py:1298: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (50). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientists have made a breakthrough in renewable energy technology, potentially revolutionizing the industry. The breakthrough could be used to create a new form of energy called clean energy. The technology could also be used in a variety of other forms of energy.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Load the BART model and tokenizer\n",
    "model_name = 'facebook/bart-large-cnn'\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Define the news article to be summarized\n",
    "article = \"In a recent development, scientists have made a breakthrough in renewable energy technology, potentially revolutionizing the industry...\"\n",
    "input_ids = tokenizer.encode(\"summarize: \" + article, return_tensors='pt')\n",
    "\n",
    "# Generate the summary\n",
    "summary_ids = model.generate(input_ids, num_beams=4, max_length=50, early_stopping=True)\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb151831-1423-4b24-a64a-8efd578a70bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaders from around the world gathered to discuss and advance global efforts in the fight against climate change. The conference took place in Paris, France, saw the participation of over 50 nations. The main focus of the discussions was on reducing carbon emissions, transitioning to renewable energy sources, and supporting nations vulnerable to the adverse effects of climateChange.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Load the BART model and tokenizer\n",
    "model_name = 'facebook/bart-large-cnn'\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Define the news article to be summarized\n",
    "article = \"\"\"\n",
    "In a major international conference held yesterday, leaders from around the world gathered to discuss and advance global efforts in the fight against climate change. The conference, which took place in Paris, France, saw the participation of over 50 nations, including major economies and developing countries alike.\n",
    "\n",
    "The main focus of the discussions was on reducing carbon emissions, transitioning to renewable energy sources, and supporting nations vulnerable to the adverse effects of climate change. Several countries pledged to increase their investments in renewable energy technologies, such as wind and solar power, aiming to significantly reduce their reliance on fossil fuels.\n",
    "\n",
    "Experts present at the conference emphasized the urgent need for action, highlighting the latest scientific research that points to the accelerating impacts of climate change on global weather patterns, ecosystems, and sea levels. The consensus was clear: without significant and immediate efforts to curb greenhouse gas emissions, the world risks catastrophic consequences in the coming decades.\n",
    "\n",
    "In addition to discussing mitigation strategies, the conference also focused on adaptation measures. Countries shared their experiences and best practices in preparing for the effects of climate change, from improving infrastructure to withstand extreme weather events to implementing sustainable agricultural practices to ensure food security.\n",
    "\n",
    "A key outcome of the conference was the establishment of a new international fund aimed at supporting climate action in developing countries. This fund will provide financial resources for both mitigation and adaptation initiatives, helping these nations implement effective climate solutions.\n",
    "\n",
    "As the conference concluded, there was a renewed sense of commitment among the participating nations to collaborate and take decisive action against climate change. While the challenges ahead are daunting, the global community appears more united than ever in its resolve to safeguard the planet for future generations.\n",
    "\"\"\"\n",
    "input_ids = tokenizer.encode(\"summarize: \" + article, return_tensors='pt', max_length=1024, truncation=True)\n",
    "\n",
    "# Generate the summary\n",
    "summary_ids = model.generate(input_ids, num_beams=4, max_length=150, early_stopping=True)\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5f51bd-f520-4163-9703-0340d8bb1ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai-book",
   "language": "python",
   "name": "gen-ai-book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
